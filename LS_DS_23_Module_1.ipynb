{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Define ML problems\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
        "- [ ] Is your problem regression or classification?\n",
        "- [ ] How is your target distributed?\n",
        "    - Classification: How many classes? Are the classes imbalanced?\n",
        "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
        "- [ ] Choose your evaluation metric(s).\n",
        "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
        "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
        "- [ ] Choose which observations you will use to train, validate, and test your model.\n",
        "    - Are some observations outliers? Will you exclude them?\n",
        "    - Will you do a random split or a time-based split?\n",
        "- [ ] Begin to clean and explore your data.\n",
        "- [ ] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
        "\n",
        "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
        "\n",
        "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# For Google reproducibility\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = \"/content/drive/My Drive/Kaggle\"\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "    #Connect to remote data\n",
        "    from google.colab import drive\n",
        "    drive.mount(DATA_PATH, force_remount=True)\n",
        "\n",
        "# Local data store on drive D:\n",
        "else:\n",
        "    DATA_PATH = \"D:/Datafiles/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Block\n",
        "import pandas as pd\n",
        "\n",
        "#sklearn\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.compose import make_column_selector as selector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part One - Dataset Basics\n",
        "\n",
        "For this week's modules I am using the asteroid dataset found on Kaggle here: https://www.kaggle.com/datasets/sakhawat18/asteroid-dataset\n",
        "(This is a cleaner version of the NASA/JPL datasets used in my portfolio projects, as such thoroughness is not needed for the daily projects)\n",
        "\n",
        "The target for this exercise will be the Potentially Hazardous Asteroid classification feature. \n",
        "Unfortunately (or, fortunately for the Earth) this feature is heavily unbalanced in favor of 'no' so we will need to adjust our metrics.\n",
        "\n",
        "This is an unbalanced binary classification problem, so we will evaluate balanced accuracy and F1 score, as well as ROC AUC.\n",
        "We will also evaluate the accuracy of the models trained on synthetically balanced datasets using eg. SMOTE techniques.\n",
        "\n",
        "The features in this dataset have a lot of redundancy due to having been merged from various sources; additionally there are\n",
        "many label features which need to be culled for modeling purposes and to prevent cross-leaking. \n",
        "\n",
        "Also worthy of note is that the PHA designation is a direct fuction of two features, absolute magnitude and minimum orbit intercept distance,\n",
        "so models will eventually be compared between the initial inference with the features included, and ones built without those features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrangling Functions\n",
        "\n",
        "def wrangle(filepath):\n",
        "\n",
        "    df = pd.read_csv(filepath, index_col=['pdes']) #pdes = primary designation number\n",
        "    \n",
        "    #drop extraneous label/index/constant columns\n",
        "    labels = ['id', 'spkid', 'full_name', 'name', 'prefix', 'orbit_id', 'equinox', 'class']\n",
        "    df.drop(columns=labels, inplace=True)\n",
        "    #drop duplicate date/distance columns\n",
        "    #NOTE: we want consistent Julian dates / AU distances\n",
        "    labels= ['epoch_mjd', 'epoch_cal', 'tp_cal', 'per_y', 'moid_ld']\n",
        "    df.drop(columns=labels, inplace=True)\n",
        "    #drop leaky columns\n",
        "    labels = ['neo']\n",
        "    df.drop(columns=labels, inplace=True)\n",
        "\n",
        "    #drop rows with no target value\n",
        "    df.dropna(subset=['pha'], inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3357: DtypeWarning: Columns (3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(938603, 30)\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 938603 entries, 1 to 2678 T-3\n",
            "Data columns (total 30 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   pha             938603 non-null  object \n",
            " 1   H               932341 non-null  float64\n",
            " 2   diameter        136209 non-null  float64\n",
            " 3   albedo          135103 non-null  float64\n",
            " 4   diameter_sigma  136081 non-null  float64\n",
            " 5   epoch           938603 non-null  float64\n",
            " 6   e               938603 non-null  float64\n",
            " 7   a               938603 non-null  float64\n",
            " 8   q               938603 non-null  float64\n",
            " 9   i               938603 non-null  float64\n",
            " 10  om              938603 non-null  float64\n",
            " 11  w               938603 non-null  float64\n",
            " 12  ma              938602 non-null  float64\n",
            " 13  ad              938599 non-null  float64\n",
            " 14  n               938603 non-null  float64\n",
            " 15  tp              938603 non-null  float64\n",
            " 16  per             938599 non-null  float64\n",
            " 17  moid            938603 non-null  float64\n",
            " 18  sigma_e         938602 non-null  float64\n",
            " 19  sigma_a         938602 non-null  float64\n",
            " 20  sigma_q         938602 non-null  float64\n",
            " 21  sigma_i         938602 non-null  float64\n",
            " 22  sigma_om        938602 non-null  float64\n",
            " 23  sigma_w         938602 non-null  float64\n",
            " 24  sigma_ma        938602 non-null  float64\n",
            " 25  sigma_ad        938598 non-null  float64\n",
            " 26  sigma_n         938602 non-null  float64\n",
            " 27  sigma_tp        938602 non-null  float64\n",
            " 28  sigma_per       938598 non-null  float64\n",
            " 29  rms             938602 non-null  float64\n",
            "dtypes: float64(29), object(1)\n",
            "memory usage: 222.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "df = wrangle(DATA_PATH + \"/Asteroids/dataset.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "print(\"\\n\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pha                    0\n",
            "H                   6262\n",
            "diameter          802394\n",
            "albedo            803500\n",
            "diameter_sigma    802522\n",
            "epoch                  0\n",
            "e                      0\n",
            "a                      0\n",
            "q                      0\n",
            "i                      0\n",
            "om                     0\n",
            "w                      0\n",
            "ma                     1\n",
            "ad                     4\n",
            "n                      0\n",
            "tp                     0\n",
            "per                    4\n",
            "moid                   0\n",
            "sigma_e                1\n",
            "sigma_a                1\n",
            "sigma_q                1\n",
            "sigma_i                1\n",
            "sigma_om               1\n",
            "sigma_w                1\n",
            "sigma_ma               1\n",
            "sigma_ad               5\n",
            "sigma_n                1\n",
            "sigma_tp               1\n",
            "sigma_per              5\n",
            "rms                    1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#print(df.value_counts())\n",
        "\n",
        "print(df.isna().sum()) #missing H may be a problem later\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LS_DS_231_assignment_JD.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "687c238b3ce093b6d05593c14198ba6d4a27c356ca33aff629c1e2e7517a29f8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
